{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dota_annotation(file_path):\n",
    "    \"\"\"Parses DOTA annotation file and returns a list of bounding boxes and labels.\"\"\"\n",
    "    annotations = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 9:  # Ensure there are enough elements\n",
    "                continue\n",
    "            coords = list(map(float, parts[:8]))  # First 8 are coordinates\n",
    "            category = parts[8]  # Category name\n",
    "            annotations.append((coords, category))\n",
    "    return annotations\n",
    "\n",
    "def load_annotations(directory):\n",
    "    \"\"\"Loads all DOTA annotations from a directory into a dictionary.\"\"\"\n",
    "    annotation_dict = {}\n",
    "    for file_path in glob.glob(os.path.join(directory, \"*.txt\")):\n",
    "        file_name = os.path.basename(file_path)\n",
    "        annotation_dict[file_name] = parse_dota_annotation(file_path)\n",
    "    return annotation_dict\n",
    "\n",
    "def polygon_to_mask(polygon, shape):\n",
    "    \"\"\"Converts a polygon to a binary mask.\"\"\"\n",
    "    mask = np.zeros(shape, dtype=np.uint8)\n",
    "    pts = np.array(polygon, dtype=np.int32).reshape(-1, 1, 2)\n",
    "    cv2.fillPoly(mask, [pts], 1)\n",
    "    return mask\n",
    "\n",
    "def compute_iou(poly1, poly2, img_size=(1024, 1024)):\n",
    "    \"\"\"Computes the Intersection over Union (IoU) between two polygons.\"\"\"\n",
    "    mask1 = polygon_to_mask(poly1, img_size)\n",
    "    mask2 = polygon_to_mask(poly2, img_size)\n",
    "    \n",
    "    intersection = np.logical_and(mask1, mask2).sum()\n",
    "    union = np.logical_or(mask1, mask2).sum()\n",
    "    \n",
    "    return intersection / union if union > 0 else 0\n",
    "\n",
    "def evaluate_dota(val_dir, pred_dir, iou_threshold=0.5):\n",
    "    \"\"\"Evaluates predictions against ground truth annotations.\"\"\"\n",
    "    val_annotations = load_annotations(val_dir)\n",
    "    pred_annotations = load_annotations(pred_dir)\n",
    "\n",
    "    categories = set()\n",
    "    for anns in val_annotations.values():\n",
    "        for _, cat in anns:\n",
    "            categories.add(cat)\n",
    "\n",
    "    results = defaultdict(lambda: {'TP': 0, 'FP': 0, 'FN': 0})\n",
    "\n",
    "    for file_name, gt_boxes in val_annotations.items():\n",
    "        pred_boxes = pred_annotations.get(file_name, [])\n",
    "\n",
    "        matched = set()\n",
    "        for pred_poly, pred_cat in pred_boxes:\n",
    "            best_iou = 0\n",
    "            best_match = None\n",
    "\n",
    "            for i, (gt_poly, gt_cat) in enumerate(gt_boxes):\n",
    "                if gt_cat == pred_cat:\n",
    "                    iou = compute_iou(pred_poly, gt_poly)\n",
    "                    if iou > best_iou:\n",
    "                        best_iou = iou\n",
    "                        best_match = i\n",
    "\n",
    "            if best_iou >= iou_threshold and best_match is not None:\n",
    "                if best_match not in matched:\n",
    "                    results[pred_cat]['TP'] += 1\n",
    "                    matched.add(best_match)\n",
    "                else:\n",
    "                    results[pred_cat]['FP'] += 1\n",
    "            else:\n",
    "                results[pred_cat]['FP'] += 1\n",
    "\n",
    "        for i, (_, gt_cat) in enumerate(gt_boxes):\n",
    "            if i not in matched:\n",
    "                results[gt_cat]['FN'] += 1\n",
    "\n",
    "    # Compute Precision, Recall, and F1-score\n",
    "    for cat, vals in results.items():\n",
    "        TP, FP, FN = vals['TP'], vals['FP'], vals['FN']\n",
    "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        results[cat]['Precision'] = precision\n",
    "        results[cat]['Recall'] = recall\n",
    "        results[cat]['F1-score'] = f1_score\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: Zigzag\n",
      "  TP: 830, FP: 712, FN: 170\n",
      "  Precision: 0.5383, Recall: 0.8300, F1-score: 0.6530\n",
      "----------------------------------------\n",
      "Category: FCBK\n",
      "  TP: 15, FP: 166, FN: 105\n",
      "  Precision: 0.0829, Recall: 0.1250, F1-score: 0.0997\n",
      "----------------------------------------\n",
      "Category: CFCBK\n",
      "  TP: 5, FP: 2, FN: 5\n",
      "  Precision: 0.7143, Recall: 0.5000, F1-score: 0.5882\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "val_dir = \"data/brickkilns/test/annfiles\"\n",
    "pred_dir = \"results/bihar/annfiles\"\n",
    "\n",
    "metrics = evaluate_dota(val_dir, pred_dir, iou_threshold=0.5)\n",
    "\n",
    "# Print results\n",
    "for category, values in metrics.items():\n",
    "    print(f\"Category: {category}\")\n",
    "    print(f\"  TP: {values['TP']}, FP: {values['FP']}, FN: {values['FN']}\")\n",
    "    print(f\"  Precision: {values['Precision']:.4f}, Recall: {values['Recall']:.4f}, F1-score: {values['F1-score']:.4f}\")\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: Zigzag\n",
      "  TP: 140, FP: 196, FN: 84\n",
      "  Precision: 0.4167, Recall: 0.6250, F1-score: 0.5000\n",
      "----------------------------------------\n",
      "Category: FCBK\n",
      "  TP: 4, FP: 13, FN: 78\n",
      "  Precision: 0.2353, Recall: 0.0488, F1-score: 0.0808\n",
      "----------------------------------------\n",
      "Category: CFCBK\n",
      "  TP: 2, FP: 1, FN: 15\n",
      "  Precision: 0.6667, Recall: 0.1176, F1-score: 0.2000\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "val_dir = \"data/m0/val/annfiles\"\n",
    "pred_dir = \"results/m0/val/annfiles\"\n",
    "\n",
    "metrics = evaluate_dota(val_dir, pred_dir, iou_threshold=0.5)\n",
    "\n",
    "# Print results\n",
    "for category, values in metrics.items():\n",
    "    print(f\"Category: {category}\")\n",
    "    print(f\"  TP: {values['TP']}, FP: {values['FP']}, FN: {values['FN']}\")\n",
    "    print(f\"  Precision: {values['Precision']:.4f}, Recall: {values['Recall']:.4f}, F1-score: {values['F1-score']:.4f}\")\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: Zigzag\n",
      "  TP: 582, FP: 730, FN: 328\n",
      "  Precision: 0.4436, Recall: 0.6396, F1-score: 0.5239\n",
      "----------------------------------------\n",
      "Category: CFCBK\n",
      "  TP: 10, FP: 2, FN: 42\n",
      "  Precision: 0.8333, Recall: 0.1923, F1-score: 0.3125\n",
      "----------------------------------------\n",
      "Category: FCBK\n",
      "  TP: 15, FP: 70, FN: 366\n",
      "  Precision: 0.1765, Recall: 0.0394, F1-score: 0.0644\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "val_dir = \"data/m0/train/annfiles\"\n",
    "pred_dir = \"results/m0/train/annfiles\"\n",
    "\n",
    "metrics = evaluate_dota(val_dir, pred_dir, iou_threshold=0.5)\n",
    "\n",
    "# Print results\n",
    "for category, values in metrics.items():\n",
    "    print(f\"Category: {category}\")\n",
    "    print(f\"  TP: {values['TP']}, FP: {values['FP']}, FN: {values['FN']}\")\n",
    "    print(f\"  Precision: {values['Precision']:.4f}, Recall: {values['Recall']:.4f}, F1-score: {values['F1-score']:.4f}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
